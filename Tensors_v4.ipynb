{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly import unfold as tl_unfold\n",
    "from tensorly.decomposition import parafac, non_negative_parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "df = pd.read_csv('isp_all.csv', header = 0, low_memory=False)\n",
    "\n",
    "# remove spaces from column headers & column cells\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "df['DX'] = df['DX'].str.strip()\n",
    "df['Feature'] = df['Feature'].str.strip()\n",
    "df['Region'] = df['Region'].str.strip()\n",
    "df['Wavelet'] = df['Wavelet'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data for wavelets D1-D6\n",
    "df = df.loc[((df.Wavelet == 'D1') | (df.Wavelet == 'D2') | (df.Wavelet == 'D3') | (df.Wavelet == 'D4') | (df.Wavelet == 'D5') | (df.Wavelet == 'D6'))]\n",
    "\n",
    "# filter data by age\n",
    "df = df.loc[(df.Age == 9)]\n",
    "\n",
    "# filter data by diagnosis\n",
    "df = df.loc[(df.DX == 'asd')]\n",
    "\n",
    "# retrieve IDs for all patients\n",
    "patients = list(set(df.ID.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 128, 6)\n",
      "(11, 64, 6)\n",
      "(11, 124, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 124, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 124, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 127, 6)\n",
      "(11, 124, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 67, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 59, 6)\n",
      "(11, 128, 6)\n",
      "(11, 103, 6)\n",
      "(11, 37, 6)\n",
      "(11, 128, 6)\n",
      "(11, 128, 6)\n",
      "(11, 89, 6)\n",
      "(11, 128, 6)\n",
      "(11, 88, 6)\n",
      "(11, 61, 6)\n",
      "(11, 35, 6)\n",
      "(11, 47, 6)\n",
      "(11, 100, 6)\n",
      "(11, 94, 6)\n",
      "(11, 78, 6)\n",
      "(11, 63, 6)\n",
      "(11, 15, 6)\n",
      "(11, 71, 6)\n",
      "(11, 111, 6)\n",
      "(11, 78, 6)\n",
      "(11, 81, 6)\n",
      "(11, 49, 6)\n",
      "(11, 44, 6)\n",
      "(11, 77, 6)\n",
      "(11, 38, 6)\n",
      "(11, 27, 6)\n",
      "(11, 43, 6)\n",
      "(11, 61, 6)\n",
      "(11, 93, 6)\n",
      "(11, 79, 6)\n",
      "(11, 18, 6)\n",
      "(11, 57, 6)\n",
      "(11, 77, 6)\n",
      "(11, 10, 6)\n",
      "(11, 59, 6)\n",
      "(11, 76, 6)\n",
      "(11, 89, 6)\n",
      "(11, 78, 6)\n",
      "(11, 70, 6)\n",
      "(11, 108, 6)\n",
      "(11, 96, 6)\n",
      "(11, 97, 6)\n",
      "(11, 32, 6)\n",
      "(11, 87, 6)\n",
      "(11, 47, 6)\n",
      "(11, 79, 6)\n",
      "(11, 45, 6)\n",
      "(11, 25, 6)\n",
      "(11, 15, 6)\n",
      "(11, 47, 6)\n",
      "(11, 63, 6)\n",
      "(11, 25, 6)\n",
      "(11, 66, 6)\n",
      "(11, 83, 6)\n",
      "(11, 53, 6)\n",
      "(11, 101, 6)\n",
      "(11, 105, 6)\n",
      "(11, 62, 6)\n",
      "(11, 65, 6)\n",
      "(11, 93, 6)\n",
      "(11, 57, 6)\n",
      "(11, 95, 6)\n",
      "(11, 54, 6)\n",
      "(11, 104, 6)\n",
      "(11, 54, 6)\n",
      "(11, 100, 6)\n",
      "(11, 128, 6)\n",
      "(11, 94, 6)\n",
      "(11, 83, 6)\n",
      "(11, 108, 6)\n",
      "(11, 76, 6)\n",
      "(11, 57, 6)\n",
      "(11, 23, 6)\n",
      "(11, 99, 6)\n",
      "(11, 75, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n",
      "(11, 128, 6)\n",
      "(11, 64, 6)\n",
      "(11, 64, 6)\n"
     ]
    }
   ],
   "source": [
    "# split data up by \"Feature\" (non-linear measure)\n",
    "measures = ['Power', 'SampE', 'hurstrs', 'RR', 'DET', 'LAM', 'DIV', 'Lentr', 'Lmax', 'Lmean', 'TT']\n",
    "\n",
    "# list of tensors\n",
    "T = []\n",
    "\n",
    "# iterate through patients\n",
    "for ID in patients:\n",
    "    \n",
    "    # get all data for one patient\n",
    "    sub0 = df.loc[(df.ID == ID)]\n",
    "    \n",
    "    # t_array is tensor array for one patient\n",
    "    t_array = []\n",
    "    \n",
    "    # get all channels for one patient\n",
    "    all_channels = list(set(sub0.Channel.tolist()))\n",
    "    \n",
    "    # create new channels array\n",
    "    channels = []\n",
    "\n",
    "    # filter out channels that have NaN values for any non-linear measure\n",
    "    for channel in all_channels:\n",
    "\n",
    "        # get data for each channel\n",
    "        sub_c = sub0.loc[(sub0.Channel == channel)]\n",
    "\n",
    "        # turn \"Value\" column into numpy array\n",
    "        row = (sub_c['Value'].to_numpy()).astype(float)\n",
    "\n",
    "        # if channel has NaN values in \"Value\", don't add channel to channels array\n",
    "        if np.any(np.isnan(row.astype(float))):\n",
    "            continue\n",
    "\n",
    "        # otherwise, concat it to channels array\n",
    "        channels.append(channel)\n",
    "    \n",
    "\n",
    "    # iterate through measures \n",
    "    for measure in measures:\n",
    "        sub1 = sub0.loc[(sub0.Feature == measure)]\n",
    "        m_array = []\n",
    "\n",
    "        for channel in channels:\n",
    "\n",
    "            # get data for one channel\n",
    "            sub2 = sub1.loc[(sub1.Channel == channel)]\n",
    "\n",
    "            # turn \"Value\" column into numpy array\n",
    "            row = (sub2['Value'].to_numpy()).astype(float)\n",
    "\n",
    "            # concat it to previous channel arrays (m_array)\n",
    "            m_array.append(row)\n",
    "\n",
    "        # once channel loop is over, concat 2d measure array to tensor array\n",
    "        t_array.append(m_array)\n",
    "    \n",
    "    # add tensor to list of tensors\n",
    "    print(np.shape(np.array(t_array)))\n",
    "    T.append(tl.tensor(t_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for tensor in T:\n",
    "    print(tensor.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
